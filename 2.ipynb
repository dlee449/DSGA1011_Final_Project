{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baM8HAwd-OFs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import base64\n",
        "import asyncio\n",
        "from io import BytesIO\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import google.generativeai as genai\n",
        "from openai import OpenAI\n",
        "from google.colab import drive, userdata\n",
        "drive.mount(\"/content/drive\")\n",
        "ROOT_DRIVE_PATH = Path(\"/content/drive/MyDrive/DSGA1011/Project\")\n",
        "SPATIAL_MM_ROOT = ROOT_DRIVE_PATH / \"Spatial-MM\"\n",
        "IMAGES_ROOT = ROOT_DRIVE_PATH / \"Spatial_MM-Benchmark\"\n",
        "COT_IMAGE_DIR = IMAGES_ROOT / \"Spatial_MM_CoT\"\n",
        "OUTPUT_DIR = ROOT_DRIVE_PATH / \"spatial_mm_outputs\"\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
        "PENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_image_pil(img: Image.Image) -> dict:\n",
        "    \"\"\"Encode a PIL image as JPEG base64.\"\"\"\n",
        "    buffered = BytesIO()\n",
        "    img.convert(\"RGB\").save(buffered, format=\"JPEG\")\n",
        "    return {\n",
        "        \"mime\": \"image/jpeg\",\n",
        "        \"base64\": base64.b64encode(buffered.getvalue()).decode(\"utf-8\"),\n",
        "    }\n",
        "\n",
        "def encode_image_path(img_path: Path) -> dict:\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    return encode_image_pil(img)\n",
        "\n",
        "def resize_and_encode_image_path(img_path: Path, scale: float) -> dict:\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    new_size = (int(img.width * scale), int(img.height * scale))\n",
        "    img = img.resize(new_size, Image.Resampling.LANCZOS)\n",
        "    return encode_image_pil(img)\n"
      ],
      "metadata": {
        "id": "OrFk6Zo1_wMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def call_gemini_async(model_name: str, prompt: str, image_b64: dict, max_tokens: int) -> str:\n",
        "    model = genai.GenerativeModel(model_name)\n",
        "    img_bytes = base64.b64decode(image_b64[\"base64\"])\n",
        "    img = Image.open(BytesIO(img_bytes))\n",
        "\n",
        "    def _call():\n",
        "        resp = model.generate_content(\n",
        "            [prompt, img],\n",
        "            generation_config={\"max_output_tokens\": max_tokens, \"temperature\": 0.0},\n",
        "        )\n",
        "        return (resp.text or \"\").strip()\n",
        "\n",
        "    loop = asyncio.get_running_loop()\n",
        "    return await loop.run_in_executor(None, _call)\n",
        "\n",
        "async def call_openai_async(model_name: str, prompt: str, image_b64: dict, max_tokens: int) -> str:\n",
        "    image_url = f\"data:{image_b64['mime']};base64,{image_b64['base64']}\"\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": prompt},\n",
        "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n",
        "            ],\n",
        "        }\n",
        "    ]\n",
        "    if \"gpt5\" in model_name:\n",
        "        kwargs = {\"max_completion_tokens\": max_tokens}\n",
        "    else:\n",
        "        kwargs = {\"max_tokens\": max_tokens}\n",
        "\n",
        "    def _call():\n",
        "        resp = openai_client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=messages,\n",
        "            temperature=0.0,\n",
        "            **kwargs,\n",
        "        )\n",
        "        return (resp.choices[0].message.content or \"\").strip()\n",
        "\n",
        "    loop = asyncio.get_running_loop()\n",
        "    return await loop.run_in_executor(None, _call)\n",
        "\n",
        "MODEL_DISPATCH = {\n",
        "    \"gemini_flash\":      lambda p, i, m: call_gemini_async(\"gemini-2.5-flash\", p, i, m),\n",
        "    \"gemini_flash_lite\": lambda p, i, m: call_gemini_async(\"gemini-2.5-flash-lite\", p, i, m),\n",
        "    \"gpt4o\":             lambda p, i, m: call_openai_async(\"gpt-4o\", p, i, m),\n",
        "    \"gpt5_mini\":         lambda p, i, m: call_openai_async(\"gpt-5-mini\", p, i, m),\n",
        "}"
      ],
      "metadata": {
        "id": "G7I6B9ax-grR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def extract_key_objects_with_gemini(question: str) -> list:\n",
        "    prompt = (\n",
        "        \"You are helping to solve visual multi-hop spatial reasoning questions.\\n\"\n",
        "        \"Given the question text below, identify the most important objects\\n\"\n",
        "        \"that must be located in the image to answer the question.\\n\\n\"\n",
        "        \"Return ONLY a JSON array of strings (no explanation).\\n\\n\"\n",
        "        f\"Question:\\n{question}\\n\"\n",
        "    )\n",
        "    model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
        "\n",
        "    def _call():\n",
        "        resp = model.generate_content(prompt)\n",
        "        return (resp.text or \"\").strip()\n",
        "\n",
        "    loop = asyncio.get_running_loop()\n",
        "    raw = await loop.run_in_executor(None, _call)\n",
        "\n",
        "    try:\n",
        "        parsed = json.loads(raw)\n",
        "        if isinstance(parsed, list):\n",
        "            return [str(x).strip() for x in parsed if str(x).strip()]\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    raw = raw.replace(\"[\", \"\").replace(\"]\", \"\")\n",
        "    parts = raw.replace(\"\\n\", \",\").split(\",\")\n",
        "    return [p.strip().strip('\"').strip(\"'\") for p in parts if p.strip()]\n",
        "\n",
        "\n",
        "async def call_vision_model_for_bboxes(image: Image.Image, key_objects: list) -> str:\n",
        "    prompt = (\n",
        "        \"Given the image and the list of object names below, return normalized bounding boxes.\\n\"\n",
        "        \"Output MUST be valid JSON in the following format:\\n\\n\"\n",
        "        \"[\\n\"\n",
        "        '  {\"object\": \"<name>\", \"bbox\": {\"x\": <float>, \"y\": <float>, \"w\": <float>, \"h\": <float>}},\\n'\n",
        "        \"  ...\\n\"\n",
        "        \"]\\n\\n\"\n",
        "        \"Coordinates x, y are the top-left corner, and w, h are width and height.\\n\"\n",
        "        \"All coordinates must be normalized to [0,1].\\n\"\n",
        "        \"If you cannot find an object, omit it from the list.\\n\\n\"\n",
        "        f\"Objects: {key_objects}\\n\"\n",
        "    )\n",
        "    model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
        "\n",
        "    def _call():\n",
        "        resp = model.generate_content([prompt, image])\n",
        "        return (resp.text or \"\").strip()\n",
        "\n",
        "    loop = asyncio.get_running_loop()\n",
        "    return await loop.run_in_executor(None, _call)\n",
        "\n",
        "def parse_bbox_response(raw: str) -> list:\n",
        "    try:\n",
        "        parsed = json.loads(raw)\n",
        "    except Exception:\n",
        "        return []\n",
        "    if not isinstance(parsed, list):\n",
        "        return []\n",
        "    out = []\n",
        "    for item in parsed:\n",
        "        try:\n",
        "            name = str(item[\"object\"]).strip()\n",
        "            box = item[\"bbox\"]\n",
        "            x, y = float(box[\"x\"]), float(box[\"y\"])\n",
        "            w, h = float(box[\"w\"]), float(box[\"h\"])\n",
        "            out.append({\"object\": name, \"x\": x, \"y\": y, \"w\": w, \"h\": h})\n",
        "        except Exception:\n",
        "            continue\n",
        "    return out"
      ],
      "metadata": {
        "id": "-Y6qiTC3-lya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def generate_spatial_record(example: dict) -> dict:\n",
        "    image_name = example[\"image_name\"]\n",
        "    question = example[\"question\"]\n",
        "\n",
        "    key_objects = await extract_key_objects_with_gemini(question)\n",
        "\n",
        "    img_path = COT_IMAGE_DIR / image_name\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "    raw_bbox = await call_vision_model_for_bboxes(img, key_objects)\n",
        "    bboxes = parse_bbox_response(raw_bbox)\n",
        "    scene_graph_text = example.get(\"reasoning\")\n",
        "\n",
        "    rec = dict(example)\n",
        "    rec[\"key_objects\"] = key_objects\n",
        "    rec[\"bboxes\"] = bboxes\n",
        "    rec[\"scene_graph_text\"] = scene_graph_text\n",
        "    return rec\n",
        "\n",
        "async def build_spatial_dataset(dataset_name: str, concurrency: int = 10):\n",
        "    if dataset_name != \"spatial_cot_multihop\":\n",
        "        raise ValueError(\"Configured only for dataset_name='spatial_cot_multihop'.\")\n",
        "\n",
        "    src_path = SPATIAL_MM_ROOT / \"data\" / \"multihop_reasoning_309.json\"\n",
        "    out_path = OUTPUT_DIR / f\"{dataset_name}_spatial_data.json\"\n",
        "\n",
        "    with open(src_path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    results = []\n",
        "    processed_ids = set()\n",
        "    if out_path.exists():\n",
        "        with open(out_path, \"r\") as f:\n",
        "            results = json.load(f)\n",
        "        processed_ids = {r[\"image_name\"] for r in results}\n",
        "\n",
        "    to_process = [ex for ex in data if ex[\"image_name\"] not in processed_ids]\n",
        "    if not to_process:\n",
        "        print(f\"Spatial data already built at {out_path}\")\n",
        "        return\n",
        "\n",
        "    sem = asyncio.Semaphore(concurrency)\n",
        "\n",
        "    async def worker(example):\n",
        "        async with sem:\n",
        "            try:\n",
        "                return await generate_spatial_record(example)\n",
        "            except Exception as e:\n",
        "                print(f\"[SPATIAL FAIL] {example['image_name']}: {e}\")\n",
        "                return None\n",
        "\n",
        "    tasks = [asyncio.create_task(worker(ex)) for ex in to_process]\n",
        "    start = time.time()\n",
        "    done = 0\n",
        "\n",
        "    for task in asyncio.as_completed(tasks):\n",
        "        rec = await task\n",
        "        done += 1\n",
        "        if rec is not None:\n",
        "            results.append(rec)\n",
        "        if done % 10 == 0:\n",
        "            with open(out_path, \"w\") as f:\n",
        "                json.dump(results, f, indent=2)\n",
        "            print(f\"[SPATIAL] {done}/{len(to_process)} processed...\")\n",
        "\n",
        "    with open(out_path, \"w\") as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "    print(f\"Saved spatial dataset to {out_path} in {time.time() - start:.1f}s\")\n"
      ],
      "metadata": {
        "id": "SRsZ1FMRALyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_CONFIGS = {\n",
        "    \"multihop_baseline_bbox\": {\n",
        "        \"template\": (\n",
        "            \"Given the bounding boxes below and the image, answer the question \"\n",
        "            \"with a single word or short phrase.\\n\\n\"\n",
        "            \"Bounding Boxes:\\n\"\n",
        "            \"{bboxes}\\n\\n\"\n",
        "            \"Question: {question}\\n\\n\"\n",
        "            \"Answer:\"\n",
        "        ),\n",
        "        \"max_tokens\": 1000,\n",
        "    },\n",
        "    \"multihop_baseline_scene_graph\": {\n",
        "        \"template\": (\n",
        "            \"Given the scene graph below and the image, answer the question \"\n",
        "            \"with a single word or short phrase.\\n\\n\"\n",
        "            \"Scene Graph (Reasoning):\\n\"\n",
        "            \"{scene_graph}\\n\\n\"\n",
        "            \"Question: {question}\\n\\n\"\n",
        "            \"Answer:\"\n",
        "        ),\n",
        "        \"max_tokens\": 1000,\n",
        "    },\n",
        "}"
      ],
      "metadata": {
        "id": "6U47Cd--AQ8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_connection_error(err: Exception) -> bool:\n",
        "    msg = str(err).lower()\n",
        "    return (\n",
        "        \"connection reset by peer\" in msg\n",
        "        or \"connection aborted\" in msg\n",
        "        or \"remote end closed connection without response\" in msg\n",
        "        or \"timed out\" in msg\n",
        "        or \"temporarily unavailable\" in msg\n",
        "        or \"429\" in msg\n",
        "        or \"503\" in msg\n",
        "    )\n",
        "\n",
        "async def query_spatial_model(dataset_name: str, prompt_key: str, model_key: str, concurrency: int = 5):\n",
        "    if dataset_name != \"spatial_cot_multihop\":\n",
        "        raise ValueError(\"Configured only for dataset_name='spatial_cot_multihop'.\")\n",
        "\n",
        "    in_path = OUTPUT_DIR / f\"{dataset_name}_spatial_data.json\"\n",
        "    if not in_path.exists():\n",
        "        raise FileNotFoundError(f\"{in_path} not found. Run build_spatial_dataset first.\")\n",
        "\n",
        "    with open(in_path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    out_path = OUTPUT_DIR / f\"{dataset_name}_{prompt_key}_{model_key}.json\"\n",
        "\n",
        "    existing = []\n",
        "    processed_ids = set()\n",
        "    if out_path.exists():\n",
        "        with open(out_path, \"r\") as f:\n",
        "            existing = json.load(f)\n",
        "        processed_ids = {r[\"image_name\"] for r in existing if r.get(\"raw_response\")}\n",
        "\n",
        "    to_process = [ex for ex in data if ex[\"image_name\"] not in processed_ids]\n",
        "    if not to_process:\n",
        "        print(f\"Already finished {model_key} / {prompt_key} on {dataset_name}\")\n",
        "        return\n",
        "\n",
        "    sem = asyncio.Semaphore(concurrency)\n",
        "    model_fn = MODEL_DISPATCH[model_key]\n",
        "    cfg = PROMPT_CONFIGS[prompt_key]\n",
        "    max_tok = cfg[\"max_tokens\"]\n",
        "\n",
        "    async def worker(example: dict):\n",
        "        image_name = example[\"image_name\"]\n",
        "        img_path = COT_IMAGE_DIR / image_name\n",
        "\n",
        "        if prompt_key == \"multihop_baseline_bbox\":\n",
        "            bboxes_str = json.dumps(example.get(\"bboxes\", []), indent=2)\n",
        "            prompt = cfg[\"template\"].format(\n",
        "                question=example[\"question\"],\n",
        "                bboxes=bboxes_str,\n",
        "            )\n",
        "        elif prompt_key == \"multihop_baseline_scene_graph\":\n",
        "            scene_graph = example.get(\"scene_graph_text\", \"\")\n",
        "            prompt = cfg[\"template\"].format(\n",
        "                question=example[\"question\"],\n",
        "                scene_graph=scene_graph,\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown prompt_key: {prompt_key}\")\n",
        "\n",
        "        max_retries = 5\n",
        "        resize_scales = [1.0, 0.9, 0.8, 0.6, 0.5]\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            async with sem:\n",
        "                try:\n",
        "                    if attempt == 0:\n",
        "                        img_b64 = encode_image_path(img_path)\n",
        "                    else:\n",
        "                        scale = resize_scales[min(attempt, len(resize_scales) - 1)]\n",
        "                        img_b64 = resize_and_encode_image_path(img_path, scale=scale)\n",
        "\n",
        "                    resp = await model_fn(prompt, img_b64, max_tok)\n",
        "                    rec = dict(example)\n",
        "                    rec[\"raw_response\"] = resp\n",
        "                    return rec\n",
        "\n",
        "                except Exception as e:\n",
        "                    if is_connection_error(e) and attempt < max_retries - 1:\n",
        "                        wait_t = 2 * (attempt + 1)\n",
        "                        print(f\"[{model_key}/{prompt_key}] {image_name} error: {e} -> retry in {wait_t}s\")\n",
        "                        await asyncio.sleep(wait_t)\n",
        "                        continue\n",
        "                    print(f\"[{model_key}/{prompt_key}] {image_name} FAILED: {e}\")\n",
        "                    return None\n",
        "\n",
        "    tasks = [asyncio.create_task(worker(ex)) for ex in to_process]\n",
        "    results = list(existing)\n",
        "    start = time.time()\n",
        "    done = 0\n",
        "    success = 0\n",
        "\n",
        "    for task in asyncio.as_completed(tasks):\n",
        "        rec = await task\n",
        "        done += 1\n",
        "        if rec is not None:\n",
        "            results.append(rec)\n",
        "            success += 1\n",
        "        if success % 10 == 0:\n",
        "            with open(out_path, \"w\") as f:\n",
        "                json.dump(results, f, indent=2)\n",
        "            print(f\"[{model_key}/{prompt_key}] {success}/{done}/{len(to_process)} saved...\")\n",
        "\n",
        "    with open(out_path, \"w\") as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "    print(\n",
        "        f\"Done {dataset_name} / {prompt_key} / {model_key}: \"\n",
        "        f\"{success}/{len(to_process)} in {time.time() - start:.1f}s\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "d9UG0e1fAXLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "running = [\n",
        "    (\"gpt4o\",             1),\n",
        "    (\"gpt5_mini\",         5),\n",
        "    (\"gemini_flash\",     15),\n",
        "    (\"gemini_flash_lite\",10),\n",
        "]\n",
        "\n",
        "prompts = [\n",
        "    \"multihop_baseline_bbox\",\n",
        "    \"multihop_baseline_scene_graph\",\n",
        "]\n",
        "\n",
        "async def main_runner():\n",
        "    dataset_name = \"spatial_cot_multihop\"\n",
        "\n",
        "    print(\">>> Building spatial dataset (if needed)...\")\n",
        "    await build_spatial_dataset(dataset_name=dataset_name, concurrency=10)\n",
        "\n",
        "    for model_key, limit in running:\n",
        "        for prompt_key in prompts:\n",
        "            print(f\"\\n>>> Starting {model_key} with {prompt_key}\")\n",
        "            await query_spatial_model(\n",
        "                dataset_name=dataset_name,\n",
        "                prompt_key=prompt_key,\n",
        "                model_key=model_key,\n",
        "                concurrency=limit,\n",
        "            )\n",
        "\n",
        "await main_runner()"
      ],
      "metadata": {
        "id": "mVRCkh4pAcCG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}